{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f7bae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Version: 2.1.1\n"
     ]
    }
   ],
   "source": [
    "# Configure MLflow Experiment\n",
    "mlflow_experiment_id = 866112\n",
    "\n",
    "# Including MLflow\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import os\n",
    "print(\"MLflow Version: %s\" % mlflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a2a0c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c065cb",
   "metadata": {},
   "source": [
    "### Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53004d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data set is synthetic dataset is scaled down 1/4 of the original dataset and it is created just for Kaggle\n",
    "data_urls = \"https://media.githubusercontent.com/media/FelixQLe/Detect_Financial_Fraud_at_Scale_with_decision_Trees/main/Synthetic_Financial_datasets_log.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6160af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_fraud_dataset = pd.read_csv(data_urls, delimiter=',', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeeb9052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#large dataset takes longer to load, so i make a copy to reuse in case\n",
    "fin_fraud_copy = fin_fraud_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37ecd5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6362620, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_fraud_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e50157",
   "metadata": {},
   "source": [
    "### Create SQL database using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87af04df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 23:44:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#Create a spark Context class\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6872f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a spark session\n",
    "spark = SparkSession.builder.appName(\"Python Spark Dataframes Financial Fruad\").config(\n",
    "        \"spark.some.config.option\", \"some-value\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35142082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_fraud_copy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25da981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data into Spark, take long\n",
    "spark_df = spark.createDataFrame(fin_fraud_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd6e62a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table view fin_fraud_table, we can treat it as sql table\n",
    "spark_df.createTempView(\"fin_fraud_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18a49389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df DataFrame which contains our simulated financial fraud detection dataset\n",
    "fin_fraud_df = spark.sql(\"select step, type, amount, nameOrig, oldbalanceOrg, newbalanceOrig, nameDest, oldbalanceDest, newbalanceDest from fin_fraud_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0d0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/03 23:47:32 ERROR Inbox: An error happened while processing message in the inbox for LocalSchedulerBackendEndpoint\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.util.Arrays.copyOf(Arrays.java:3236)\n",
      "\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n",
      "\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n",
      "\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n",
      "\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115)\n",
      "\tat org.apache.spark.scheduler.TaskSetManager.prepareLaunchingTask(TaskSetManager.scala:519)\n",
      "\tat org.apache.spark.scheduler.TaskSetManager.$anonfun$resourceOffer$2(TaskSetManager.scala:483)\n",
      "\tat org.apache.spark.scheduler.TaskSetManager$$Lambda$2295/1953838613.apply(Unknown Source)\n",
      "\tat scala.Option.map(Option.scala:230)\n",
      "\tat org.apache.spark.scheduler.TaskSetManager.resourceOffer(TaskSetManager.scala:459)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$resourceOfferSingleTaskSet$2(TaskSchedulerImpl.scala:397)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$resourceOfferSingleTaskSet$2$adapted(TaskSchedulerImpl.scala:392)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$Lambda$2286/1674543924.apply(Unknown Source)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$resourceOfferSingleTaskSet$1(TaskSchedulerImpl.scala:392)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$Lambda$2285/621877361.apply$mcVI$sp(Unknown Source)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.resourceOfferSingleTaskSet(TaskSchedulerImpl.scala:383)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$resourceOffers$20(TaskSchedulerImpl.scala:589)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$resourceOffers$20$adapted(TaskSchedulerImpl.scala:584)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$Lambda$2284/1270202704.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$resourceOffers$16(TaskSchedulerImpl.scala:584)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$resourceOffers$16$adapted(TaskSchedulerImpl.scala:557)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"dispatcher-event-loop-2\" java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.util.Arrays.copyOf(Arrays.java:3236)\n",
      "\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n",
      "\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n",
      "\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n",
      "\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:115)\n",
      "\tat org.apache.spark.scheduler.TaskSetManager.prepareLaunchingTask(TaskSetManager.scala:519)\n",
      "\tat org.apache.spark.scheduler.TaskSetManager.$anonfun$resourceOffer$2(TaskSetManager.scala:483)\n",
      "\tat org.apache.spark.scheduler.TaskSetManager$$Lambda$2295/1953838613.apply(Unknown Source)\n",
      "\tat scala.Option.map(Option.scala:230)\n",
      "\tat org.apache.spark.scheduler.TaskSetManager.resourceOffer(TaskSetManager.scala:459)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$resourceOfferSingleTaskSet$2(TaskSchedulerImpl.scala:397)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$resourceOfferSingleTaskSet$2$adapted(TaskSchedulerImpl.scala:392)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$Lambda$2286/1674543924.apply(Unknown Source)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$resourceOfferSingleTaskSet$1(TaskSchedulerImpl.scala:392)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$Lambda$2285/621877361.apply$mcVI$sp(Unknown Source)\n",
      "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.resourceOfferSingleTaskSet(TaskSchedulerImpl.scala:383)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$resourceOffers$20(TaskSchedulerImpl.scala:589)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$resourceOffers$20$adapted(TaskSchedulerImpl.scala:584)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$Lambda$2284/1270202704.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$resourceOffers$16(TaskSchedulerImpl.scala:584)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.$anonfun$resourceOffers$16$adapted(TaskSchedulerImpl.scala:557)\n",
      "[Stage 0:>                                                          (0 + 0) / 1]\r"
     ]
    }
   ],
   "source": [
    "fin_fraud_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad980613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the schema of your data \n",
    "fin_fraud_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column orgDiff and destDiff based on the difference between Originating and Destination\n",
    "fin_fraud_df = fin_fraud_df.withColumn(\"orgDiff\",\n",
    "                            fin_fraud_df.newbalanceOrig - \n",
    "                                       fin_fraud_df.oldbalanceOrg).withColumn(\"destDiff\",\n",
    "                            fin_fraud_df.newbalanceDest - fin_fraud_df.oldbalanceDest)\n",
    "    \n",
    "#create temporary view\n",
    "fin_fraud_df.createOrReplaceTempView(\"financials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca81c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#review the new table\n",
    "fin_fraud_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1dd8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_fraud_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715fd973",
   "metadata": {},
   "source": [
    "### Exploring Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0badd8d",
   "metadata": {},
   "source": [
    "#### What are the type of transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52439c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select type, count(1) from financials group by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0cc4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "lighthouse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
